{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t2QqX9tOpVit"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "seed_value = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "2uWKfKItphb7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('fnspid_prices_title_sentiment.csv')\n",
        "df = df.set_index('date')\n",
        "df.index = pd.to_datetime(df.index)\n",
        "stocks = ['ENB','GS','WFC','GME','D','EA','CMCSA','DHI','CRM','VRTX',\n",
        "        'SPWR','GILD','WDC','BX','AAL']\n",
        "df = df[df['Stock_symbol'].isin(stocks)]"
      ],
      "metadata": {
        "id": "qBWPk4P2pi2B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['target_binary'] = (df['movement_percent'] >= 0).astype(int)\n",
        "df['target_binary'] = df['target_binary'].shift(-1)\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "-xq1e_1-pj5a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sequences(df: DataFrame, window_size: int, feature_cols: list, target: str):\n",
        "    X, y = [], []\n",
        "\n",
        "    features = df[feature_cols].to_numpy()\n",
        "    y_vals = df[target].to_numpy()\n",
        "\n",
        "    for i in range(len(df) - window_size):\n",
        "        X.append(features[i:i + window_size])\n",
        "        y.append(y_vals[i + window_size])\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "dxeslO63pmDj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef, confusion_matrix, roc_auc_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "window_size = 20\n",
        "feature_cols = ['open_logret', 'high_logret', 'low_logret', 'close_logret', 'volume_logret']\n",
        "target = 'target_binary'\n",
        "l2_value = 1e-4\n",
        "batch_size = 8\n",
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "results = []\n",
        "\n",
        "for symbol in df['Stock_symbol'].unique():\n",
        "    print(f\"\\n{'='*40}\\nTraining model for: {symbol}\\n{'='*40}\")\n",
        "\n",
        "    df_symbol = df[df['Stock_symbol'] == symbol].copy()\n",
        "    price_cols = ['open', 'high', 'low', 'close', 'volume']\n",
        "    for col in price_cols:\n",
        "      df_symbol[f'{col}_logret'] = np.log(df_symbol[col]) - np.log(df_symbol[col].shift(1))\n",
        "    df_symbol.dropna(inplace=True)\n",
        "\n",
        "    train = df_symbol.loc['2014-01-01':'2021-03-29']\n",
        "    val = df_symbol.loc['2021-03-30':'2022-07-28']\n",
        "    test = df_symbol.loc['2022-07-29':'2023-12-01']\n",
        "\n",
        "    if len(train) < window_size * 2 or len(test) < window_size:\n",
        "        print(f\"Not enough data for {symbol}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    X_train, y_train = sequences(train, window_size=window_size, feature_cols=feature_cols, target=target)\n",
        "    X_val, y_val = sequences(val, window_size=window_size, feature_cols=feature_cols, target=target)\n",
        "    X_test, y_test = sequences(test, window_size=window_size, feature_cols=feature_cols, target=target)\n",
        "\n",
        "    X_train = np.array(X_train); y_train = np.array(y_train)\n",
        "    X_val = np.array(X_val); y_val = np.array(y_val)\n",
        "    X_test = np.array(X_test); y_test = np.array(y_test)\n",
        "\n",
        "    for X in [X_train, X_val, X_test]:\n",
        "        np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0, copy=False)\n",
        "\n",
        "    mean = np.mean(X_train, axis=(0,1))\n",
        "    std = np.std(X_train, axis=(0,1))\n",
        "    std[std == 0] = 1e-8\n",
        "\n",
        "    # X_train_norm = (X_train - mean) / std\n",
        "    # X_val_norm = (X_val - mean) / std\n",
        "    # X_test_norm = (X_test - mean) / std\n",
        "\n",
        "    unique, counts = np.unique(y_test, return_counts=True)\n",
        "    dist = dict(zip(unique, counts))\n",
        "    total = counts.sum()\n",
        "    pct_0 = 100 * dist.get(0, 0) / total\n",
        "    pct_1 = 100 * dist.get(1, 0) / total\n",
        "    print(f\"Test class distribution: 0s={pct_0:.2f}%, 1s={pct_1:.2f}%\")\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape=(window_size, len(feature_cols))),\n",
        "        Conv1D(filters=16, kernel_size=3, strides=1, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(filters=8, kernel_size=3, strides=1, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        LSTM(16),\n",
        "        Dropout(0.1),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid', kernel_regularizer=l2(l2_value))\n",
        "    ])\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC', 'accuracy'])\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    y_val_pred_prob = model.predict(X_val)\n",
        "    y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
        "\n",
        "    y_test_pred_prob = model.predict(X_test)\n",
        "    y_test_pred = (y_test_pred_prob > 0.5).astype(int)\n",
        "\n",
        "    val_auc = roc_auc_score(y_val, y_val_pred_prob)\n",
        "    val_f1 = f1_score(y_val, y_val_pred)\n",
        "    val_mcc = matthews_corrcoef(y_val, y_val_pred)\n",
        "\n",
        "    test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
        "    test_f1 = f1_score(y_test, y_test_pred)\n",
        "    test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "    test_acc = np.mean(y_test_pred.flatten() == y_test.flatten())\n",
        "    test_cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"[{symbol}] Test AUC: {test_auc:.4f} | F1: {test_f1:.4f} | MCC: {test_mcc:.4f} | ACC: {test_acc:.4f}\")\n",
        "    print(f\"Confusion matrix:\\n{test_cm}\\n\")\n",
        "\n",
        "    results.append({\n",
        "        'Symbol': symbol,\n",
        "        'Val_AUC': val_auc,\n",
        "        'Val_F1': val_f1,\n",
        "        'Val_MCC': val_mcc,\n",
        "        'Test_AUC': test_auc,\n",
        "        'Test_F1': test_f1,\n",
        "        'Test_MCC': test_mcc,\n",
        "        'Test_ACC': test_acc,\n",
        "        'Test_0%': pct_0,\n",
        "        'Test_1%': pct_1\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n=== Summary of all stocks ===\")\n",
        "print(results_df.sort_values('Test_AUC', ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTAETVO-pnla",
        "outputId": "48157638-a4c7-449d-9602-c94e219f521a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Training model for: AAL\n",
            "========================================\n",
            "Test class distribution: 0s=48.28%, 1s=51.72%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "[AAL] Test AUC: 0.4764 | F1: 0.6173 | MCC: 0.0125 | ACC: 0.5141\n",
            "Confusion matrix:\n",
            "[[ 39 115]\n",
            " [ 40 125]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: BX\n",
            "========================================\n",
            "Test class distribution: 0s=47.34%, 1s=52.66%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "[BX] Test AUC: 0.5274 | F1: 0.6134 | MCC: 0.0426 | ACC: 0.5298\n",
            "Confusion matrix:\n",
            "[[ 50 101]\n",
            " [ 49 119]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: CMCSA\n",
            "========================================\n",
            "Test class distribution: 0s=48.59%, 1s=51.41%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "[CMCSA] Test AUC: 0.5524 | F1: 0.6608 | MCC: 0.0198 | ACC: 0.5172\n",
            "Confusion matrix:\n",
            "[[ 15 140]\n",
            " [ 14 150]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: CRM\n",
            "========================================\n",
            "Test class distribution: 0s=47.02%, 1s=52.98%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "[CRM] Test AUC: 0.5177 | F1: 0.6519 | MCC: 0.0998 | ACC: 0.5580\n",
            "Confusion matrix:\n",
            "[[ 46 104]\n",
            " [ 37 132]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: D\n",
            "========================================\n",
            "Test class distribution: 0s=49.53%, 1s=50.47%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "[D] Test AUC: 0.5599 | F1: 0.6316 | MCC: 0.0363 | ACC: 0.5172\n",
            "Confusion matrix:\n",
            "[[ 33 125]\n",
            " [ 29 132]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: DHI\n",
            "========================================\n",
            "Test class distribution: 0s=45.45%, 1s=54.55%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "[DHI] Test AUC: 0.5832 | F1: 0.7059 | MCC: 0.0000 | ACC: 0.5455\n",
            "Confusion matrix:\n",
            "[[  0 145]\n",
            " [  0 174]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: EA\n",
            "========================================\n",
            "Test class distribution: 0s=47.96%, 1s=52.04%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "[EA] Test AUC: 0.5367 | F1: 0.6818 | MCC: -0.0538 | ACC: 0.5172\n",
            "Confusion matrix:\n",
            "[[  0 153]\n",
            " [  1 165]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: ENB\n",
            "========================================\n",
            "Test class distribution: 0s=50.78%, 1s=49.22%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "[ENB] Test AUC: 0.5278 | F1: 0.5097 | MCC: 0.0464 | ACC: 0.5235\n",
            "Confusion matrix:\n",
            "[[88 74]\n",
            " [78 79]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: GILD\n",
            "========================================\n",
            "Test class distribution: 0s=47.34%, 1s=52.66%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "[GILD] Test AUC: 0.5296 | F1: 0.6820 | MCC: -0.0099 | ACC: 0.5235\n",
            "Confusion matrix:\n",
            "[[  4 147]\n",
            " [  5 163]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: GME\n",
            "========================================\n",
            "Test class distribution: 0s=52.98%, 1s=47.02%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "[GME] Test AUC: 0.5290 | F1: 0.5480 | MCC: 0.0141 | ACC: 0.4984\n",
            "Confusion matrix:\n",
            "[[ 62 107]\n",
            " [ 53  97]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: GS\n",
            "========================================\n",
            "Test class distribution: 0s=49.53%, 1s=50.47%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "[GS] Test AUC: 0.5148 | F1: 0.4494 | MCC: 0.0865 | ACC: 0.5392\n",
            "Confusion matrix:\n",
            "[[112  46]\n",
            " [101  60]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: SPWR\n",
            "========================================\n",
            "Test class distribution: 0s=55.80%, 1s=44.20%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "[SPWR] Test AUC: 0.5182 | F1: 0.3790 | MCC: -0.0039 | ACC: 0.5172\n",
            "Confusion matrix:\n",
            "[[118  60]\n",
            " [ 94  47]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: VRTX\n",
            "========================================\n",
            "Test class distribution: 0s=44.20%, 1s=55.80%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "[VRTX] Test AUC: 0.5379 | F1: 0.5276 | MCC: 0.0432 | ACC: 0.5172\n",
            "Confusion matrix:\n",
            "[[79 62]\n",
            " [92 86]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: WDC\n",
            "========================================\n",
            "Test class distribution: 0s=50.16%, 1s=49.84%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "[WDC] Test AUC: 0.5225 | F1: 0.5985 | MCC: 0.0192 | ACC: 0.5078\n",
            "Confusion matrix:\n",
            "[[ 45 115]\n",
            " [ 42 117]]\n",
            "\n",
            "\n",
            "========================================\n",
            "Training model for: WFC\n",
            "========================================\n",
            "Test class distribution: 0s=48.43%, 1s=51.57%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "[WFC] Test AUC: 0.5623 | F1: 0.6158 | MCC: 0.1088 | ACC: 0.5566\n",
            "Confusion matrix:\n",
            "[[ 64  90]\n",
            " [ 51 113]]\n",
            "\n",
            "\n",
            "=== Summary of all stocks ===\n",
            "   Symbol   Val_AUC    Val_F1   Val_MCC  Test_AUC   Test_F1  Test_MCC  \\\n",
            "5     DHI  0.494833  0.666667  0.000000  0.583195  0.705882  0.000000   \n",
            "14    WFC  0.546667  0.610354  0.100306  0.562282  0.615804  0.108806   \n",
            "4       D  0.531066  0.616505 -0.004763  0.559950  0.631579  0.036309   \n",
            "2   CMCSA  0.548299  0.676660  0.023816  0.552400  0.660793  0.019834   \n",
            "12   VRTX  0.627671  0.614907  0.216125  0.537852  0.527607  0.043249   \n",
            "6      EA  0.485049  0.677824  0.000000  0.536735  0.681818 -0.053837   \n",
            "8    GILD  0.499820  0.663848  0.000000  0.529644  0.682008 -0.009866   \n",
            "9     GME  0.557835  0.508251  0.055882  0.529034  0.548023  0.014065   \n",
            "7     ENB  0.508873  0.513595 -0.019073  0.527797  0.509677  0.046427   \n",
            "1      BX  0.548264  0.635000  0.062312  0.527357  0.613402  0.042586   \n",
            "13    WDC  0.463375  0.560847 -0.038015  0.522543  0.598465  0.019197   \n",
            "11   SPWR  0.548125  0.382979  0.063375  0.518209  0.379032 -0.003940   \n",
            "3     CRM  0.544613  0.570694 -0.051120  0.517712  0.651852  0.099805   \n",
            "10     GS  0.520709  0.342105  0.016130  0.514781  0.449438  0.086542   \n",
            "0     AAL  0.558052  0.606061  0.123319  0.476387  0.617284  0.012529   \n",
            "\n",
            "    Test_ACC    Test_0%    Test_1%  \n",
            "5   0.545455  45.454545  54.545455  \n",
            "14  0.556604  48.427673  51.572327  \n",
            "4   0.517241  49.529781  50.470219  \n",
            "2   0.517241  48.589342  51.410658  \n",
            "12  0.517241  44.200627  55.799373  \n",
            "6   0.517241  47.962382  52.037618  \n",
            "8   0.523511  47.335423  52.664577  \n",
            "9   0.498433  52.978056  47.021944  \n",
            "7   0.523511  50.783699  49.216301  \n",
            "1   0.529781  47.335423  52.664577  \n",
            "13  0.507837  50.156740  49.843260  \n",
            "11  0.517241  55.799373  44.200627  \n",
            "3   0.557994  47.021944  52.978056  \n",
            "10  0.539185  49.529781  50.470219  \n",
            "0   0.514107  48.275862  51.724138  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results_df['Test_ACC'].mean())\n",
        "print(results_df['Test_AUC'].mean())\n",
        "print(results_df['Test_MCC'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L79xQ4B8qLYC",
        "outputId": "d4bc4ce1-7c69-44a5-ef3c-2e21ec075ce8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.525508172157489\n",
            "0.5330584730216387\n",
            "0.030780408905092024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPg4cQT-yMZK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
